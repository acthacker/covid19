{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Province/State Country/Region      Lat      Long  1/22/20  1/23/20  1/24/20  \\\n0            NaN       Thailand  15.0000  101.0000        2        3        5   \n1            NaN          Japan  36.0000  138.0000        2        1        2   \n2            NaN      Singapore   1.2833  103.8333        0        1        3   \n3            NaN          Nepal  28.1667   84.2500        0        0        0   \n4            NaN       Malaysia   2.5000  112.5000        0        0        0   \n\n   1/25/20  1/26/20  1/27/20  ...  3/7/20  3/8/20  3/9/20  3/10/20  3/11/20  \\\n0        7        8        8  ...      50      50      50       53       59   \n1        2        4        4  ...     461     502     511      581      639   \n2        3        4        5  ...     138     150     150      160      178   \n3        1        1        1  ...       1       1       1        1        1   \n4        3        4        4  ...      93      99     117      129      149   \n\n   3/12/20  3/13/20  3/14/20  3/15/20  3/16/20  \n0       70       75       82      114      147  \n1      639      701      773      839      825  \n2      178      200      212      226      243  \n3        1        1        1        1        1  \n4      149      197      238      428      566  \n\n[5 rows x 59 columns]\n"
    }
   ],
   "source": [
    "#Imports Pandas and Numpy which have features for data science work not included in base Python\n",
    "#I will wait to import other tools until the cells where I need them so I can write the explanations in those posts.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Reads data from source and imports into Pandas dataframes\n",
    "data_confirmed = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv\")\n",
    "data_deaths = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv\")\n",
    "data_recovered = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv\")\n",
    "\n",
    "#sample data\n",
    "print(data_confirmed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Province/State Country/Region      Lat      Long  1/22/20  1/23/20  \\\n98         Washington             US  47.4009 -121.4905        0        0   \n99           New York             US  42.1657  -74.9481        0        0   \n100        California             US  36.1162 -119.6816        0        0   \n101     Massachusetts             US  42.2302  -71.5301        0        0   \n102  Diamond Princess             US  35.4437  139.6380        0        0   \n\n     1/24/20  1/25/20  1/26/20  1/27/20  ...  3/7/20  3/8/20  3/9/20  3/10/20  \\\n98         0        0        0        0  ...       0       0       0      267   \n99         0        0        0        0  ...       0       0       0      173   \n100        0        0        0        0  ...       0       0       0      144   \n101        0        0        0        0  ...       0       0       0       92   \n102        0        0        0        0  ...      45      45      45       46   \n\n     3/11/20  3/12/20  3/13/20  3/14/20  3/15/20  3/16/20  \n98       366      442      568      572      643      904  \n99       220      328      421      525      732      967  \n100      177      221      282      340      426      557  \n101       95      108      123      138      164      197  \n102       46       46       46       46       46       47  \n\n[5 rows x 59 columns]\n       Province/State Country/Region      Lat      Long  1/22/20  1/23/20  \\\n98         Washington             US  47.4009 -121.4905        0        0   \n99           New York             US  42.1657  -74.9481        0        0   \n100        California             US  36.1162 -119.6816        0        0   \n101     Massachusetts             US  42.2302  -71.5301        0        0   \n102  Diamond Princess             US  35.4437  139.6380        0        0   \n\n     1/24/20  1/25/20  1/26/20  1/27/20  ...  3/7/20  3/8/20  3/9/20  3/10/20  \\\n98         0        0        0        0  ...       0       0       0       23   \n99         0        0        0        0  ...       0       0       0        0   \n100        0        0        0        0  ...       0       0       0        2   \n101        0        0        0        0  ...       0       0       0        0   \n102        0        0        0        0  ...       0       0       0        0   \n\n     3/11/20  3/12/20  3/13/20  3/14/20  3/15/20  3/16/20  \n98        29       31       37       37       40       48  \n99         0        0        0        2        3       10  \n100        3        4        4        5        6        7  \n101        0        0        0        0        0        0  \n102        0        0        0        0        0        0  \n\n[5 rows x 59 columns]\n       Province/State Country/Region      Lat      Long  1/22/20  1/23/20  \\\n98         Washington             US  47.4009 -121.4905        0        0   \n99           New York             US  42.1657  -74.9481        0        0   \n100        California             US  36.1162 -119.6816        0        0   \n101     Massachusetts             US  42.2302  -71.5301        0        0   \n102  Diamond Princess             US  35.4437  139.6380        0        0   \n\n     1/24/20  1/25/20  1/26/20  1/27/20  ...  3/7/20  3/8/20  3/9/20  3/10/20  \\\n98         0        0        0        0  ...       0       0       0        1   \n99         0        0        0        0  ...       0       0       0        0   \n100        0        0        0        0  ...       0       0       0        2   \n101        0        0        0        0  ...       0       0       0        1   \n102        0        0        0        0  ...       0       0       0        0   \n\n     3/11/20  3/12/20  3/13/20  3/14/20  3/15/20  3/16/20  \n98         1        1        1        1        1        1  \n99         0        0        0        0        0        0  \n100        2        6        6        6        6        6  \n101        1        1        1        1        1        1  \n102        0        0        0        0        0        0  \n\n[5 rows x 59 columns]\n"
    }
   ],
   "source": [
    "#Filters each of the three to contain only US data\n",
    "data_confirmed = data_confirmed[data_confirmed[\"Country/Region\"].str.contains(\"US\")]\n",
    "data_deaths = data_deaths[data_deaths[\"Country/Region\"].str.contains(\"US\")]\n",
    "data_recovered = data_recovered[data_recovered[\"Country/Region\"].str.contains(\"US\")]\n",
    "\n",
    "#Sample data again\n",
    "print(data_confirmed.head())\n",
    "print(data_deaths.head())\n",
    "print(data_recovered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Province/State Country/Region      Lat      Long  1/22/20  1/23/20  1/24/20  \\\n0        Alabama             US  32.3182  -86.9023        0        0        0   \n1         Alaska             US  61.3707 -152.4044        0        0        0   \n2        Arizona             US  33.7298 -111.4312        0        0        0   \n3       Arkansas             US  34.9697  -92.3731        0        0        0   \n4     California             US  36.1162 -119.6816        0        0        0   \n\n   1/25/20  1/26/20  1/27/20  ...  3/7/20  3/8/20  3/9/20  3/10/20  3/11/20  \\\n0        0        0        0  ...       0       0       0        0        0   \n1        0        0        0  ...       0       0       0        0        0   \n2        0        0        0  ...       0       0       0        6        9   \n3        0        0        0  ...       0       0       0        0        1   \n4        0        0        0  ...       0       0       0      144      177   \n\n   3/12/20  3/13/20  3/14/20  3/15/20  3/16/20  \n0        0        5        6       12       29  \n1        0        1        1        1        1  \n2        9        9       12       13       18  \n3        6        6       12       16       22  \n4      221      282      340      426      557  \n\n[5 rows x 59 columns]\n"
    }
   ],
   "source": [
    "#Filters out rows containing \"Princess\"\n",
    "data_confirmed = data_confirmed[~data_confirmed[\"Province/State\"].str.contains(\"Princess\")]\n",
    "data_deaths = data_deaths[~data_deaths[\"Province/State\"].str.contains(\"Princess\")]\n",
    "data_recovered = data_recovered[~data_recovered[\"Province/State\"].str.contains(\"Princess\")]\n",
    "\n",
    "#Filters out rows containing \",\" which catches the city entries\n",
    "data_confirmed = data_confirmed[~data_confirmed[\"Province/State\"].str.contains(\",\")]\n",
    "data_deaths = data_deaths[~data_deaths[\"Province/State\"].str.contains(\",\")]\n",
    "data_recovered = data_recovered[~data_recovered[\"Province/State\"].str.contains(\",\")]\n",
    "\n",
    "#Filters out US territories\n",
    "data_confirmed = data_confirmed[~data_confirmed[\"Province/State\"].isin([\"Guam\", \"Puerto Rico\", \"Virgin Islands\"])]\n",
    "data_deaths = data_deaths[~data_deaths[\"Province/State\"].isin([\"Guam\", \"Puerto Rico\", \"Virgin Islands\"])]\n",
    "data_recovered = data_recovered[~data_recovered[\"Province/State\"].isin([\"Guam\", \"Puerto Rico\", \"Virgin Islands\"])]\n",
    "\n",
    "#Sort the dataframe alphabetically by state name\n",
    "data_confirmed.sort_values(by=[\"Province/State\"], ascending = True, inplace = True)\n",
    "data_deaths.sort_values(by=[\"Province/State\"], ascending = True, inplace = True)\n",
    "data_recovered.sort_values(by=[\"Province/State\"], ascending = True, inplace = True)\n",
    "\n",
    "#Resets indexing just to make everything a little cleaner to work with\n",
    "data_confirmed = data_confirmed.reset_index(drop = True)\n",
    "data_deaths = data_deaths.reset_index(drop = True)\n",
    "data_recovered = data_recovered.reset_index(drop = True)\n",
    "\n",
    "#Sampling again\n",
    "print(data_confirmed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "NAME  population\n0                Alabama     4903185\n1                 Alaska      731545\n2                Arizona     7278717\n3               Arkansas     3017804\n4             California    39512223\n5               Colorado     5758736\n6            Connecticut     3565287\n7               Delaware      973764\n8   District of Columbia      705749\n9                Florida    21477737\n10               Georgia    10617423\n11                Hawaii     1415872\n12                 Idaho     1787065\n13              Illinois    12671821\n14               Indiana     6732219\n15                  Iowa     3155070\n16                Kansas     2913314\n17              Kentucky     4467673\n18             Louisiana     4648794\n19                 Maine     1344212\n20              Maryland     6045680\n21         Massachusetts     6892503\n22              Michigan     9986857\n23             Minnesota     5639632\n24           Mississippi     2976149\n25              Missouri     6137428\n26               Montana     1068778\n27              Nebraska     1934408\n28                Nevada     3080156\n29         New Hampshire     1359711\n30            New Jersey     8882190\n31            New Mexico     2096829\n32              New York    19453561\n33        North Carolina    10488084\n34          North Dakota      762062\n35                  Ohio    11689100\n36              Oklahoma     3956971\n37                Oregon     4217737\n38          Pennsylvania    12801989\n39          Rhode Island     1059361\n40        South Carolina     5148714\n41          South Dakota      884659\n42             Tennessee     6829174\n43                 Texas    28995881\n44                  Utah     3205958\n45               Vermont      623989\n46              Virginia     8535519\n47            Washington     7614893\n48         West Virginia     1792147\n49             Wisconsin     5822434\n50               Wyoming      578759\n"
    }
   ],
   "source": [
    "#State population estimates found at https://www.census.gov/data/datasets/time-series/demo/popest/2010s-national-total.html#par_textimage_401631162\n",
    "data_pop = pd.read_csv(\"state_pop.csv\")\n",
    "\n",
    "print(data_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Province/State      Lat      Long\n0        Alabama  32.3182  -86.9023\n1         Alaska  61.3707 -152.4044\n2        Arizona  33.7298 -111.4312\n3       Arkansas  34.9697  -92.3731\n4     California  36.1162 -119.6816\n"
    }
   ],
   "source": [
    "#Grabs the state, latitude, and longitude columns to initiate the dataframe\n",
    "train_df = data_confirmed[[\"Province/State\", \"Lat\", \"Long\"]]\n",
    "#Drops the rows for the US territories\n",
    "train_df = train_df[~train_df[\"Province/State\"].isin([\"Guam\", \"Puerto Rico\", \"Virgin Islands\"])]\n",
    "#Same for the second dataframe\n",
    "predict_df = data_confirmed[[\"Province/State\", \"Lat\", \"Long\"]]\n",
    "predict_df = train_df[~train_df[\"Province/State\"].isin([\"Guam\", \"Puerto Rico\", \"Virgin Islands\"])]\n",
    "\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Province/State</th>\n      <th>Lat</th>\n      <th>Long</th>\n      <th>population</th>\n      <th>active</th>\n      <th>1_day</th>\n      <th>3_day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alabama</td>\n      <td>32.3182</td>\n      <td>-86.9023</td>\n      <td>4903185</td>\n      <td>12</td>\n      <td>6</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alaska</td>\n      <td>61.3707</td>\n      <td>-152.4044</td>\n      <td>731545</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Arizona</td>\n      <td>33.7298</td>\n      <td>-111.4312</td>\n      <td>7278717</td>\n      <td>12</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arkansas</td>\n      <td>34.9697</td>\n      <td>-92.3731</td>\n      <td>3017804</td>\n      <td>16</td>\n      <td>4</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>California</td>\n      <td>36.1162</td>\n      <td>-119.6816</td>\n      <td>39512223</td>\n      <td>414</td>\n      <td>86</td>\n      <td>205</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "  Province/State      Lat      Long  population  active  1_day  3_day\n0        Alabama  32.3182  -86.9023     4903185      12      6     12\n1         Alaska  61.3707 -152.4044      731545       1      0      1\n2        Arizona  33.7298 -111.4312     7278717      12      1      4\n3       Arkansas  34.9697  -92.3731     3017804      16      4     10\n4     California  36.1162 -119.6816    39512223     414     86    205"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Creating variables for current active cases\n",
    "#Subtracts the COVID deaths and the COVID recoveries from the confirmed cases to give a current, active count\n",
    "pred_curr_day_active = data_confirmed.iloc[:, -1].subtract(data_deaths.iloc[:,-1].add(data_recovered.iloc[:,-1]))\n",
    "train_curr_day_active = data_confirmed.iloc[:, -2].subtract(data_deaths.iloc[:,-2].add(data_recovered.iloc[:,-2]))\n",
    "\n",
    "#Setting the result we are trying to predict in the training model\n",
    "#The result to predict is the number of new cases between yeterday and today using data leading to today\n",
    "train_target = data_confirmed.iloc[:,-1].subtract(data_confirmed.iloc[:,-2])\n",
    "\n",
    "#Creating variables for the past day's increases in cases\n",
    "train_increase = data_confirmed.iloc[:,-2].subtract(data_confirmed.iloc[:,-3])\n",
    "train_3day_increase = data_confirmed.iloc[:,-2].subtract(data_confirmed.iloc[:,-5])\n",
    "\n",
    "#Creating variables for the current day's increases in cases\n",
    "pred_increase = data_confirmed.iloc[:,-1].subtract(data_confirmed.iloc[:,-2])\n",
    "pred_3day_increase = data_confirmed.iloc[:,-1].subtract(data_confirmed.iloc[:,-4])\n",
    "\n",
    "#Adds the columns to the training dataframe\n",
    "train_df[\"population\"] = data_pop[\"population\"]\n",
    "train_df[\"active\"] = train_curr_day_active\n",
    "train_df[\"1_day\"] = train_increase\n",
    "train_df[\"3_day\"] = train_3day_increase\n",
    "\n",
    "#Adds the columns to the prediction dataframe\n",
    "predict_df[\"population\"] = data_pop[\"population\"]\n",
    "predict_df[\"active\"] = pred_curr_day_active\n",
    "predict_df[\"1_day\"] = pred_increase\n",
    "predict_df[\"3_day\"] = pred_3day_increase\n",
    "\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing needed libraries\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "\n",
    "#Initiate function which takes lat and lon from two different points as imputs\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "\n",
    "    #Estmated redius of the Earth\n",
    "    R = 3958.8\n",
    "\n",
    "    #Transforms the lat and lon into radians for the caulculation\n",
    "    lat1 = radians(lat1)\n",
    "    lon1 = radians(lon1)\n",
    "    lat2 = radians(lat2)\n",
    "    lon2 = radians(lon2)\n",
    "\n",
    "    #Programmed version of the Haversine equation\n",
    "    #Found here: https://en.wikipedia.org/wiki/Haversine_formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "\n",
    "    #Returns the great circle distance between the two points.\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Province/State</th>\n      <th>Lat</th>\n      <th>Long</th>\n      <th>population</th>\n      <th>active</th>\n      <th>1_day</th>\n      <th>3_day</th>\n      <th>nearby</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alabama</td>\n      <td>32.3182</td>\n      <td>-86.9023</td>\n      <td>4903185</td>\n      <td>29</td>\n      <td>17</td>\n      <td>24</td>\n      <td>185</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alaska</td>\n      <td>61.3707</td>\n      <td>-152.4044</td>\n      <td>731545</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Arizona</td>\n      <td>33.7298</td>\n      <td>-111.4312</td>\n      <td>7278717</td>\n      <td>17</td>\n      <td>5</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arkansas</td>\n      <td>34.9697</td>\n      <td>-92.3731</td>\n      <td>3017804</td>\n      <td>22</td>\n      <td>6</td>\n      <td>16</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>California</td>\n      <td>36.1162</td>\n      <td>-119.6816</td>\n      <td>39512223</td>\n      <td>544</td>\n      <td>131</td>\n      <td>275</td>\n      <td>44</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "  Province/State      Lat      Long  population  active  1_day  3_day  nearby\n0        Alabama  32.3182  -86.9023     4903185      29     17     24     185\n1         Alaska  61.3707 -152.4044      731545       1      0      0       0\n2        Arizona  33.7298 -111.4312     7278717      17      5      9       0\n3       Arkansas  34.9697  -92.3731     3017804      22      6     16      19\n4     California  36.1162 -119.6816    39512223     544    131    275      44"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Initializing the lists to populate with nearby cases\n",
    "nearby_cases_pred = []\n",
    "nearby_cases_train = []\n",
    "\n",
    "#This line begins this for loop and allows for calling each row in the Pandas dataframe\n",
    "for index, row in predict_df.iterrows():\n",
    "    #This line gives a baseline of 0 for the nearby case count\n",
    "    case_count = 0\n",
    "    #This is a second, internal loop of every state again to compate against the selected state\n",
    "    for i, r in predict_df.iterrows():\n",
    "        #Calls the Haversine function and returns the distance\n",
    "        hav = haversine(row[\"Lat\"], row[\"Long\"], r[\"Lat\"], r[\"Long\"])\n",
    "        #If that distance is less than 250 and more than 0 (so it does not catch the same state)...\n",
    "        #For example: comparing WV to WV in the inner loop would return 0, and we want nearby, not in-state cases here\n",
    "        if hav <= 250 and hav > 0:\n",
    "            #Add the case count for the nearby state to the running case count total\n",
    "            case_count += r[\"active\"]\n",
    "    #Appends the total nearby cases to the list initiated above\n",
    "    nearby_cases_pred.append(case_count)\n",
    "\n",
    "#Same code again for the training data\n",
    "for index, row in train_df.iterrows():\n",
    "    case_count = 0\n",
    "    for i, r in train_df.iterrows():\n",
    "        hav = haversine(row[\"Lat\"], row[\"Long\"], r[\"Lat\"], r[\"Long\"])\n",
    "        if hav <= 250 and hav > 0:\n",
    "            case_count += r[\"active\"]\n",
    "    nearby_cases_train.append(case_count)\n",
    "\n",
    "#Takes the lists created and adds them as new columns in the dataframes.\n",
    "train_df[\"nearby\"] = nearby_cases_train\n",
    "predict_df[\"nearby\"] = nearby_cases_pred\n",
    "\n",
    "display(predict_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Coefficient</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>nearby</th>\n      <td>0.001153</td>\n    </tr>\n    <tr>\n      <th>active</th>\n      <td>0.453221</td>\n    </tr>\n    <tr>\n      <th>1_day</th>\n      <td>-0.614545</td>\n    </tr>\n    <tr>\n      <th>3_day</th>\n      <td>0.077439</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "        Coefficient\nnearby     0.001153\nactive     0.453221\n1_day     -0.614545\n3_day      0.077439"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Intercept: -1.354738573622054\nR^2 value: 0.95\n"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "Y = train_target\n",
    "X = train_df[[\"nearby\", \"active\",  \"1_day\", \"3_day\"]]\n",
    "\n",
    "regressor = LinearRegression().fit(X, Y)\n",
    "coeff_df = pd.DataFrame(regressor.coef_, X.columns, columns=['Coefficient'])\n",
    "display(coeff_df)\n",
    "print(\"Intercept: \" + str(regressor.intercept_))\n",
    "print(\"R^2 value: \" + str(round(regressor.score(X, Y),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Predicted</th>\n      <th>Actual</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.495397</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.824079</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.779119</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.230294</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>149.330339</td>\n      <td>131</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    Predicted  Actual\n0    1.495397      17\n1   -0.824079       0\n2    3.779119       5\n3    4.230294       6\n4  149.330339     131"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train_pred = regressor.predict(X)\n",
    "\n",
    "training_predictions = pd.DataFrame({\"Predicted\": y_train_pred, \"Actual\":Y})\n",
    "\n",
    "display(training_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>State</th>\n      <th>Predicted new cases</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alabama</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alaska</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Arizona</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arkansas</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>California</td>\n      <td>186</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Colorado</td>\n      <td>61</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Connecticut</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Delaware</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>District of Columbia</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Florida</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Georgia</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Hawaii</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Idaho</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Illinois</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Indiana</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Iowa</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Kansas</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Kentucky</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Louisiana</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Maine</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Maryland</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Massachusetts</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Michigan</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Minnesota</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Mississippi</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Missouri</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Montana</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Nebraska</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Nevada</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>New Hampshire</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>New Jersey</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>New Mexico</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>New York</td>\n      <td>331</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>North Carolina</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>North Dakota</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Ohio</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Oklahoma</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Oregon</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Pennsylvania</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>Rhode Island</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>South Carolina</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>South Dakota</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>Tennessee</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>Texas</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>Utah</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>Vermont</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>Virginia</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>Washington</td>\n      <td>252</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>West Virginia</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>Wisconsin</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>Wyoming</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                   State  Predicted new cases\n0                Alabama                    3\n1                 Alaska                    0\n2                Arizona                    4\n3               Arkansas                    6\n4             California                  186\n5               Colorado                   61\n6            Connecticut                   12\n7               Delaware                    4\n8   District of Columbia                    6\n9                Florida                   50\n10               Georgia                   46\n11                Hawaii                    2\n12                 Idaho                    1\n13              Illinois                   43\n14               Indiana                    8\n15                  Iowa                    7\n16                Kansas                    2\n17              Kentucky                    7\n18             Louisiana                   39\n19                 Maine                    5\n20              Maryland                   14\n21         Massachusetts                   74\n22              Michigan                   13\n23             Minnesota                   15\n24           Mississippi                    4\n25              Missouri                    1\n26               Montana                    2\n27              Nebraska                    7\n28                Nevada                    8\n29         New Hampshire                    6\n30            New Jersey                   42\n31            New Mexico                    4\n32              New York                  331\n33        North Carolina                   15\n34          North Dakota                    0\n35                  Ohio                   16\n36              Oklahoma                    2\n37                Oregon                   16\n38          Pennsylvania                   31\n39          Rhode Island                   10\n40        South Carolina                   12\n41          South Dakota                    2\n42             Tennessee                   16\n43                 Texas                   32\n44                  Utah                   12\n45               Vermont                    4\n46              Virginia                   20\n47            Washington                  252\n48         West Virginia                    0\n49             Wisconsin                   13\n50               Wyoming                    0"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_prediction = predict_df[[\"nearby\", \"active\", \"1_day\", \"3_day\"]]\n",
    "\n",
    "y_pred = regressor.predict(x_prediction)\n",
    "\n",
    "adjusted_predictions = []\n",
    "\n",
    "for i in y_pred:\n",
    "    if i <= 0:\n",
    "        adjusted_predictions.append(0)\n",
    "    else:\n",
    "        adjusted_predictions.append(int(i.round()))\n",
    "\n",
    "predicted_by_state = pd.DataFrame({\"State\": predict_df[\"Province/State\"], \"Predicted new cases\": adjusted_predictions})\n",
    "display(predicted_by_state)"
   ]
  }
 ]
}